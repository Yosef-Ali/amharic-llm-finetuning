"""
Content Validator for Amharic Text
Real-time validation of generated content using extraction
"""

import re
import time
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass
from enum import Enum

from ..extraction.schemas import get_schema_by_domain


class ValidationLevel(Enum):
    """Validation strictness levels."""
    MINIMAL = "minimal"
    STANDARD = "standard"
    STRICT = "strict"


class IssueType(Enum):
    """Types of validation issues."""
    LENGTH = "length"
    ENTITIES = "entities"
    RELATIONSHIPS = "relationships"
    DOMAIN_COMPLIANCE = "domain_compliance"
    QUALITY = "quality"
    COHERENCE = "coherence"


@dataclass
class ValidationIssue:
    """Individual validation issue."""
    issue_type: IssueType
    severity: str  # "error", "warning", "info"
    message: str
    suggestion: str = ""
    character_position: Optional[Tuple[int, int]] = None


@dataclass
class ValidationResult:
    """Result of content validation."""
    is_valid: bool
    overall_score: float
    issues: List[ValidationIssue]
    suggestions: List[str]
    validation_time: float
    
    # Detailed scores
    length_score: float = 0.0
    entity_score: float = 0.0
    relationship_score: float = 0.0
    domain_score: float = 0.0
    quality_score: float = 0.0
    coherence_score: float = 0.0


class ContentValidator:
    """Validates Amharic content against extraction schemas and quality metrics."""
    
    def __init__(self, validation_level: ValidationLevel = ValidationLevel.STANDARD):
        self.validation_level = validation_level
        self.amharic_patterns = self._initialize_amharic_patterns()
        self.domain_keywords = self._initialize_domain_keywords()
    
    def _initialize_amharic_patterns(self) -> Dict[str, List[str]]:
        """Initialize Amharic language patterns."""
        return {
            "formal_titles": [r"á‹¶/áˆ­\s+\w+", r"á•/áˆ­\s+\w+", r"á‹ˆ/áˆ®\s+\w+", r"áŠ á‰¶\s+\w+"],
            "organizations": [r"\w+\s+áˆšáŠ’áˆµá‰´áˆ­", r"\w+\s+á‹©áŠ’á‰¨áˆ­áˆµá‰²", r"\w+\s+á‹µáˆ­áŒ…á‰µ", r"\w+\s+áŠ©á‰£áŠ•á‹«"],
            "locations": [r"áŠ á‹²áˆµ áŠ á‰ á‰£", r"á‰£áˆ…áˆ­ á‹³áˆ­", r"áˆ˜á‰€áˆŒ", r"áŒáŠ•á‹°áˆ­", r"\w+\s+áŠ­áˆáˆ"],
            "dates": [r"\d+\s+á‹“\.áˆ", r"\w+\s+\d+", r"\d+/\d+/\d+", r"á‰ \w+\s+\d+"],
            "sentence_endings": [r"á¢", r"!", r"?", r"á¡"],
            "conjunctions": [r"áŠ¥áŠ“", r"á‹ˆá‹­áˆ", r"áŠáŒˆáˆ­ áŒáŠ•", r"áˆµáˆˆá‹šáˆ…", r"áŠ¨á‹šá‹«áˆ"]
        }
    
    def _initialize_domain_keywords(self) -> Dict[str, List[str]]:
        """Initialize domain-specific keywords."""
        return {
            "news": ["á‹œáŠ“", "áˆªá–áˆ­á‰µ", "áˆ˜áˆ¨áŒƒ", "áŠ­áŠ•á‹áŠ•", "áˆµá‰¥áˆ°á‰£", "á‹á‹­á‹­á‰µ"],
            "government": ["áˆ˜áŠ•áŒáˆ¥á‰µ", "á–áˆŠáˆ²", "áˆ•áŒ", "áŠ á‹‹áŒ…", "áˆšáŠ’áˆµá‰´áˆ­", "áŠ­áˆáˆ"],
            "education": ["á‰µáˆáˆ…áˆ­á‰µ", "á‹©áŠ’á‰¨áˆ­áˆµá‰²", "á‰°áˆ›áˆª", "áˆ˜áˆáˆ…áˆ­", "áˆáˆ­áˆáˆ­", "á‹²áŒáˆª"],
            "healthcare": ["áŒ¤áŠ“", "áˆ•áŠ­áˆáŠ“", "áˆ†áˆµá’á‰³áˆ", "á‹¶áŠ­á‰°áˆ­", "á‰ áˆ½á‰³", "áˆ•áŠ­áˆáŠ“"],
            "culture": ["á‰£áˆ…áˆ", "á‹ˆáŒ", "á‰ á‹“áˆ", "áˆµáˆ­á‹“á‰µ", "áˆ™á‹šá‰ƒ", "áŒ¥á‰ á‰¥"]
        }
    
    def validate_content(self, 
                        text: str,
                        domain: str = "news",
                        extraction_result: Optional[Dict[str, Any]] = None,
                        target_length: Optional[Tuple[int, int]] = None) -> ValidationResult:
        """Validate content comprehensively."""
        
        start_time = time.time()
        issues = []
        suggestions = []
        
        # Set target length if not provided
        if target_length is None:
            target_length = self._get_default_length_range(domain)
        
        # Perform different validation checks
        length_score = self._validate_length(text, target_length, issues, suggestions)
        entity_score = self._validate_entities(text, domain, extraction_result, issues, suggestions)
        relationship_score = self._validate_relationships(text, domain, extraction_result, issues, suggestions)
        domain_score = self._validate_domain_compliance(text, domain, issues, suggestions)
        quality_score = self._validate_quality(text, issues, suggestions)
        coherence_score = self._validate_coherence(text, issues, suggestions)
        
        # Calculate overall score
        scores = [length_score, entity_score, relationship_score, domain_score, quality_score, coherence_score]
        weights = [0.15, 0.25, 0.15, 0.20, 0.15, 0.10]  # Entity and domain most important
        
        overall_score = sum(score * weight for score, weight in zip(scores, weights))
        
        # Determine validity based on validation level
        validity_threshold = {
            ValidationLevel.MINIMAL: 0.6,
            ValidationLevel.STANDARD: 0.7,
            ValidationLevel.STRICT: 0.8
        }
        
        is_valid = overall_score >= validity_threshold[self.validation_level]
        
        validation_time = time.time() - start_time
        
        return ValidationResult(
            is_valid=is_valid,
            overall_score=overall_score,
            issues=issues,
            suggestions=suggestions,
            validation_time=validation_time,
            length_score=length_score,
            entity_score=entity_score,
            relationship_score=relationship_score,
            domain_score=domain_score,
            quality_score=quality_score,
            coherence_score=coherence_score
        )
    
    def _validate_length(self, 
                        text: str, 
                        target_length: Tuple[int, int],
                        issues: List[ValidationIssue],
                        suggestions: List[str]) -> float:
        """Validate text length."""
        
        word_count = len(text.split())
        min_length, max_length = target_length
        
        if word_count < min_length:
            issues.append(ValidationIssue(
                issue_type=IssueType.LENGTH,
                severity="warning",
                message=f"áŒ½áˆ‘á‰ á‰ áŒ£áˆ áŠ áŒ­áˆ­ áŠá‹ ({word_count} á‰ƒáˆ‹á‰µ, á‰¢á‹«áŠ•áˆµ {min_length} á‹«áˆµáˆáˆáŒ‹áˆ)",
                suggestion="á‰°áŒ¨áˆ›áˆª á‹áˆ­á‹áˆ­ áˆ˜áˆ¨áŒƒ áŠ¥áŠ“ áˆáˆ³áˆŒá‹á‰½ á‹«áŠ­áˆ‰"
            ))
            suggestions.append("áŒ½áˆ‘á‰áŠ• á‰ á‰°áŒ¨áˆ›áˆª á‹áˆ­á‹áˆ­ áˆ˜áˆ¨áŒƒ á‹«áˆ°á‰")
            score = max(0.3, word_count / min_length)
            
        elif word_count > max_length:
            issues.append(ValidationIssue(
                issue_type=IssueType.LENGTH,
                severity="info",
                message=f"áŒ½áˆ‘á‰ áˆ¨áŒ…áˆ áŠá‹ ({word_count} á‰ƒáˆ‹á‰µ, áŠ¨{max_length} á‰ áˆ‹á‹­)",
                suggestion="á‹‹áŠ“á‹á‰¹áŠ• áŠáŒ¥á‰¦á‰½ áˆ‹á‹­ á‰°áˆ˜áˆµáˆ­á‰°á‹ á‹«áˆ³áŒ¥áˆ©"
            ))
            suggestions.append("áŒ½áˆ‘á‰áŠ• á‹‹áŠ“ á‹‹áŠ“ áŠáŒ¥áŠ¦á‰½ áˆ‹á‹­ á‰ áˆ›á‰°áŠ®áˆ­ á‹«áˆ³áŒ¥áˆ©")
            score = max(0.7, 1.0 - (word_count - max_length) / max_length * 0.3)
            
        else:
            score = 1.0
        
        return score
    
    def _validate_entities(self, 
                          text: str,
                          domain: str,
                          extraction_result: Optional[Dict[str, Any]],
                          issues: List[ValidationIssue],
                          suggestions: List[str]) -> float:
        """Validate entity presence and quality."""
        
        score = 1.0
        
        if extraction_result:
            entities = extraction_result.get("entities", {})
            total_entities = sum(len(v) for v in entities.values())
            
            # Check minimum entity count
            min_entities = self._get_minimum_entity_count(domain)
            if total_entities < min_entities:
                issues.append(ValidationIssue(
                    issue_type=IssueType.ENTITIES,
                    severity="warning",
                    message=f"á‰ á‰‚ áŠ áŠ«áˆ‹á‰µ áŠ áˆá‰°áŒˆáŠ™áˆ ({total_entities} áŠ¨{min_entities} á‰¢á‹«áŠ•áˆµ)",
                    suggestion="á‰°áŒ¨áˆ›áˆª áˆµáˆá‰½á£ á‰¦á‰³á‹á‰½ áŠ¥áŠ“ á‰€áŠ–á‰½ á‹«áŠ­áˆ‰"
                ))
                suggestions.append("á‰ áŒ½áˆ‘á‰ á‹áˆµáŒ¥ á‰°áŒ¨áˆ›áˆª áŠ áŠ«áˆ‹á‰µ (áˆµáˆá‰½á£ á‰¦á‰³á‹á‰½á£ á‰€áŠ–á‰½) á‹«áŠ­áˆ‰")
                score *= max(0.4, total_entities / min_entities)
            
            # Check domain-specific entities
            schema = get_schema_by_domain(domain)
            expected_entity_types = set(schema.get("entities", {}).keys())
            found_entity_types = set(entities.keys())
            
            missing_types = expected_entity_types - found_entity_types
            if missing_types:
                missing_amharic = [self._entity_type_to_amharic(et) for et in missing_types]
                issues.append(ValidationIssue(
                    issue_type=IssueType.ENTITIES,
                    severity="warning",
                    message=f"á‹¨áˆšáŠ¨á‰°áˆ‰á‰µ á‹¨áˆšáŒ á‰ á‰ áŠ áŠ«áˆ‹á‰µ áˆµáˆˆá‰³áˆ³á‰ƒáˆ: {', '.join(missing_amharic)}",
                    suggestion=f"áŠ¥á‰£áŠ­á‹ {', '.join(missing_amharic)} á‹«áŠ­áˆ‰"
                ))
                suggestions.append(f"á‹¨áˆšáŠ¨á‰°áˆ‰á‰µ áŠ áŠ«áˆ‹á‰µ á‹«áŠ­áˆ‰: {', '.join(missing_amharic)}")
                coverage_score = len(found_entity_types) / len(expected_entity_types)
                score *= max(0.5, coverage_score)
        
        else:
            # Basic pattern-based validation
            entity_patterns_found = 0
            for pattern_type, patterns in self.amharic_patterns.items():
                if pattern_type in ["formal_titles", "organizations", "locations", "dates"]:
                    for pattern in patterns:
                        if re.search(pattern, text):
                            entity_patterns_found += 1
                            break
            
            if entity_patterns_found < 2:
                issues.append(ValidationIssue(
                    issue_type=IssueType.ENTITIES,
                    severity="warning",
                    message="á‰ áŒ½áˆ‘á‰ á‹áˆµáŒ¥ á‰ á‰‚ áŠ áŠ«áˆ‹á‰µ áŠ áˆá‰°áŒˆáŠ™áˆ",
                    suggestion="áˆµáˆá‰½á£ á‰°á‰‹áˆ›á‰µá£ á‰¦á‰³á‹á‰½ áŠ¥áŠ“ á‰€áŠ–á‰½ á‹«áŠ­áˆ‰"
                ))
                suggestions.append("á‰ áŒ½áˆ‘á‰ á‹áˆµáŒ¥ á‰°áŒ¨áˆ›áˆª áŠ áŠ«áˆ‹á‰µ á‹«áŠ­áˆ‰")
                score *= max(0.5, entity_patterns_found / 4)
        
        return score
    
    def _validate_relationships(self, 
                               text: str,
                               domain: str,
                               extraction_result: Optional[Dict[str, Any]],
                               issues: List[ValidationIssue],
                               suggestions: List[str]) -> float:
        """Validate relationships between entities."""
        
        score = 1.0
        
        if extraction_result:
            relationships = extraction_result.get("relationships", [])
            
            # Check for basic relationships
            if len(relationships) == 0:
                # Look for relationship indicators in text
                relationship_indicators = [
                    r"\w+\s+á‰ \w+\s+á‹­áˆ°áˆ«áˆ",  # works at
                    r"\w+\s+á‰ \w+\s+á‹­áŒˆáŠ›áˆ",  # located in
                    r"á‰ \w+\s+\w+\s+á‰°áŠ¨áˆµá‰·áˆ", # happened at
                    r"\w+\s+áŠ¥áŠ“\s+\w+",      # basic connections
                ]
                
                indicators_found = 0
                for pattern in relationship_indicators:
                    if re.search(pattern, text):
                        indicators_found += 1
                
                if indicators_found == 0:
                    issues.append(ValidationIssue(
                        issue_type=IssueType.RELATIONSHIPS,
                        severity="info",
                        message="á‰ áŠ áŠ«áˆ‹á‰µ áˆ˜áŠ«áŠ¨áˆ áŒáŠ•áŠ™áŠá‰µ áŠ áˆá‰°áŒˆáŠ˜áˆ",
                        suggestion="á‹¨áŠ áŠ«áˆ‹á‰µ áˆ˜áŠ«áŠ¨áˆ á‹«áˆˆá‹áŠ• áŒáŠ•áŠ™áŠá‰µ á‹­áŒáˆˆáŒ¹"
                    ))
                    suggestions.append("á‰ áˆ°á‹á‰½á£ á‰¦á‰³á‹á‰½ áŠ¥áŠ“ á‰°á‰‹áˆ›á‰µ áˆ˜áŠ«áŠ¨áˆ á‹«áˆˆá‹áŠ• áŒáŠ•áŠ™áŠá‰µ á‹­áŒáˆˆáŒ¹")
                    score *= 0.7
        
        return score
    
    def _validate_domain_compliance(self, 
                                   text: str,
                                   domain: str,
                                   issues: List[ValidationIssue],
                                   suggestions: List[str]) -> float:
        """Validate compliance with domain expectations."""
        
        domain_keywords = self.domain_keywords.get(domain, [])
        if not domain_keywords:
            return 1.0
        
        # Check for domain-specific keywords
        keywords_found = 0
        for keyword in domain_keywords:
            if keyword in text:
                keywords_found += 1
        
        keyword_score = min(1.0, keywords_found / len(domain_keywords) * 2)  # Allow 50% coverage for full score
        
        if keyword_score < 0.5:
            domain_amharic = {
                "news": "á‹œáŠ“",
                "government": "áˆ˜áŠ•áŒáˆ¥á‰µ", 
                "education": "á‰µáˆáˆ…áˆ­á‰µ",
                "healthcare": "áŒ¤áŠ“",
                "culture": "á‰£áˆ…áˆ"
            }.get(domain, domain)
            
            issues.append(ValidationIssue(
                issue_type=IssueType.DOMAIN_COMPLIANCE,
                severity="warning",
                message=f"áŒ½áˆ‘á‰ á‹¨{domain_amharic} á‹“á‹­áŠá‰µ áŠ á‹­áˆ˜áˆµáˆáˆ",
                suggestion=f"áŠ¨{domain_amharic} áŒ‹áˆ­ á‹¨áˆšáŒˆáŠ“áŠ™ á‰ƒáˆ‹á‰µ áŠ¥áŠ“ áŒ­á‰¥áŒ¦á‰½ á‹«áŠ­áˆ‰"
            ))
            suggestions.append(f"áŠ¨{domain_amharic} á‹˜áˆ­á áŒ‹áˆ­ á‹¨áˆšáŒˆáŠ“áŠ™ á‰ƒáˆ‹á‰µ á‹«áŠ­áˆ‰")
        
        return keyword_score
    
    def _validate_quality(self, 
                         text: str,
                         issues: List[ValidationIssue],
                         suggestions: List[str]) -> float:
        """Validate general text quality."""
        
        score = 1.0
        
        # Check sentence structure
        sentences = self._split_sentences(text)
        if len(sentences) < 2:
            issues.append(ValidationIssue(
                issue_type=IssueType.QUALITY,
                severity="warning",  
                message="áŒ½áˆ‘á‰ á‰ áŒ£áˆ áŒ¥á‰‚á‰µ á‹“áˆ¨áá‰° áŠáŒˆáˆ®á‰½ áŠ áˆ‰á‰µ",
                suggestion="á‰°áŒ¨áˆ›áˆª á‹“áˆ¨áá‰° áŠáŒˆáˆ®á‰½ á‹«áŠ­áˆ‰"
            ))
            suggestions.append("áŒ½áˆ‘á‰áŠ• á‰ á‰ áˆ­áŠ«á‰³ á‹“áˆ¨áá‰° áŠáŒˆáˆ®á‰½ á‹«áˆ°á‰")
            score *= 0.7
        
        # Check for proper sentence endings
        sentences_with_endings = 0
        ending_patterns = self.amharic_patterns["sentence_endings"]
        
        for sentence in sentences:
            for pattern in ending_patterns:
                if sentence.strip().endswith(pattern):
                    sentences_with_endings += 1
                    break
        
        if len(sentences) > 0:
            ending_score = sentences_with_endings / len(sentences)
            if ending_score < 0.8:
                issues.append(ValidationIssue(
                    issue_type=IssueType.QUALITY,
                    severity="info",
                    message="áŠ áŠ•á‹³áŠ•á‹µ á‹“áˆ¨áá‰° áŠáŒˆáˆ®á‰½ á‰µáŠ­áŠ­áˆˆáŠ› áˆ˜á‹°áˆá‹°áˆšá‹« á‹¨áˆ‹á‰¸á‹áˆ",
                    suggestion="á‹“áˆ¨áá‰° áŠáŒˆáˆ®á‰½áŠ• á‰ á£ á¢ á‹ˆá‹­áˆ ! á‹«áŒ áŠ“á‰€á‰"
                ))
                score *= max(0.8, ending_score)
        
        # Check for repetitive content
        words = text.split()
        unique_words = set(words)
        if len(words) > 20:  # Only check for longer texts
            diversity_ratio = len(unique_words) / len(words)
            if diversity_ratio < 0.5:
                issues.append(ValidationIssue(
                    issue_type=IssueType.QUALITY,
                    severity="info",
                    message="áŒ½áˆ‘á‰ á‰°á‹°áŒ‹áŒ‹áˆš á‰ƒáˆ‹á‰µ á‹­á‹Ÿáˆ",
                    suggestion="á‹¨á‰°áˆˆá‹«á‹© á‰ƒáˆ‹á‰µ áŠ¥áŠ“ áŠ áŒˆáˆ‹áˆˆáŒ¾á‰½ á‹­áŒ á‰€áˆ™"
                ))
                suggestions.append("á‹¨á‰°áˆˆá‹«á‹© á‰ƒáˆ‹á‰µ áŠ¥áŠ“ áŠ áŒˆáˆ‹áˆˆáŒ¾á‰½ á‰ áˆ˜áŒ á‰€áˆ áŒ½áˆ‘á‰áŠ• á‹«á‰¥á‹›á‹™")
                score *= max(0.7, diversity_ratio / 0.5)  # Scale to 0.5 = 1.0 score
        
        return score
    
    def _validate_coherence(self, 
                           text: str,
                           issues: List[ValidationIssue],
                           suggestions: List[str]) -> float:
        """Validate text coherence and flow."""
        
        score = 1.0
        
        sentences = self._split_sentences(text)
        if len(sentences) < 2:
            return score
        
        # Check for conjunctions and transitions
        conjunctions = self.amharic_patterns["conjunctions"]
        conjunction_count = 0
        
        for conjunction in conjunctions:
            conjunction_count += len(re.findall(conjunction, text))
        
        # Expect at least one conjunction per 3 sentences
        expected_conjunctions = max(1, len(sentences) // 3)
        if conjunction_count < expected_conjunctions:
            issues.append(ValidationIssue(
                issue_type=IssueType.COHERENCE,
                severity="info",
                message="á‹“áˆ¨áá‰° áŠáŒˆáˆ®á‰½ á‰ á‰ á‰‚ áˆáŠ”á‰³ áŠ áˆá‰°áŒˆáŠ“áŠ™áˆ",
                suggestion="á‹¨áˆšáŠ¨á‰°áˆ‰á‰µáŠ• áˆ›áŒˆáŠ“áŠ› á‰ƒáˆ‹á‰µ á‹­áŒ á‰€áˆ™: áŠ¥áŠ“á£ áŠáŒˆáˆ­ áŒáŠ•á£ áˆµáˆˆá‹šáˆ…"
            ))
            suggestions.append("á‰ á‹“áˆ¨áá‰° áŠáŒˆáˆ®á‰½ áˆ˜áŠ«áŠ¨áˆ áˆ›áŒˆáŠ“áŠ› á‰ƒáˆ‹á‰µ á‹­áŒ á‰€áˆ™")
            score *= max(0.7, conjunction_count / expected_conjunctions)
        
        return score
    
    def _split_sentences(self, text: str) -> List[str]:
        """Split text into sentences."""
        # Split on Amharic sentence endings
        sentences = re.split(r'[á¢!?á¡]\s*', text)
        return [s.strip() for s in sentences if s.strip()]
    
    def _get_default_length_range(self, domain: str) -> Tuple[int, int]:
        """Get default length range for domain."""
        ranges = {
            "news": (100, 300),
            "government": (150, 400),
            "education": (120, 350),
            "healthcare": (100, 300),
            "culture": (80, 250)
        }
        return ranges.get(domain, (100, 300))
    
    def _get_minimum_entity_count(self, domain: str) -> int:
        """Get minimum expected entity count for domain."""
        counts = {
            "news": 4,
            "government": 3,
            "education": 3,
            "healthcare": 3,
            "culture": 2
        }
        return counts.get(domain, 3)
    
    def _entity_type_to_amharic(self, entity_type: str) -> str:
        """Convert entity type to Amharic name."""
        mappings = {
            "people": "áˆ°á‹á‰½",
            "organizations": "á‹µáˆ­áŒ…á‰¶á‰½",
            "locations": "á‰¦á‰³á‹á‰½",
            "dates": "á‰€áŠ–á‰½",
            "officials": "áˆƒáˆ‹áŠá‹á‰½",
            "regions": "áŠ­áˆáˆá‰½",
            "policies": "á–áˆŠáˆ²á‹á‰½",
            "laws": "áˆ•áŒá‰½"
        }
        return mappings.get(entity_type, entity_type)
    
    def generate_improvement_report(self, validation_result: ValidationResult) -> str:
        """Generate a detailed improvement report."""
        
        report_lines = []
        report_lines.append("ğŸ“Š á‹¨áŒ½áˆ‘á áŒáˆáŒˆáˆ› áˆªá–áˆ­á‰µ")
        report_lines.append("=" * 50)
        
        # Overall assessment
        if validation_result.is_valid:
            report_lines.append("âœ… áŒ½áˆ‘á‰ áŒ¥áˆ«á‰µ á‹«áˆˆá‹ áŠá‹")
        else:
            report_lines.append("âš ï¸  áŒ½áˆ‘á‰ áˆ›áˆ»áˆ»á‹« á‹«áˆµáˆáˆáŒˆá‹‹áˆ")
        
        report_lines.append(f"ğŸ¯ áŠ áŒ á‰ƒáˆ‹á‹­ á‹áŒ¤á‰µ: {validation_result.overall_score:.2f}")
        report_lines.append("")
        
        # Detailed scores
        report_lines.append("ğŸ“‹ á‹áˆ­á‹áˆ­ á‹áŒ¤á‰¶á‰½:")
        report_lines.append(f"   áˆ­á‹áˆ˜á‰µ: {validation_result.length_score:.2f}")
        report_lines.append(f"   áŠ áŠ«áˆ‹á‰µ: {validation_result.entity_score:.2f}")
        report_lines.append(f"   áŒáŠ•áŠ™áŠá‰¶á‰½: {validation_result.relationship_score:.2f}")
        report_lines.append(f"   á‹“á‹­áŠá‰µ á‰°á‹›áˆ›áŒ…áŠá‰µ: {validation_result.domain_score:.2f}")
        report_lines.append(f"   áŒ¥áˆ«á‰µ: {validation_result.quality_score:.2f}")
        report_lines.append(f"   á‰…áŠ•áŒ…á‰µ: {validation_result.coherence_score:.2f}")
        report_lines.append("")
        
        # Issues
        if validation_result.issues:
            report_lines.append("âš ï¸  á‹¨á‰°áŒˆáŠ™ á‰½áŒáˆ®á‰½:")
            for issue in validation_result.issues:
                severity_icon = {"error": "âŒ", "warning": "âš ï¸", "info": "â„¹ï¸"}.get(issue.severity, "â€¢")
                report_lines.append(f"   {severity_icon} {issue.message}")
                if issue.suggestion:
                    report_lines.append(f"      ğŸ’¡ {issue.suggestion}")
            report_lines.append("")
        
        # Suggestions
        if validation_result.suggestions:
            report_lines.append("ğŸ’¡ áˆ›áˆ»áˆ»á‹« áˆ€áˆ³á‰¦á‰½:")
            for suggestion in validation_result.suggestions:
                report_lines.append(f"   â€¢ {suggestion}")
            report_lines.append("")
        
        report_lines.append(f"â±ï¸  áŒáˆáŒˆáˆ› áŒŠá‹œ: {validation_result.validation_time:.3f} áˆ°áŠ¨áŠ•á‹µ")
        
        return "\n".join(report_lines)