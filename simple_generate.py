#!/usr/bin/env python3
"""Simple Amharic text generation without checkpoints."""

import sys
from pathlib import Path
import random

# Add src to path
sys.path.insert(0, str(Path(__file__).parent / "src"))

from amharichnet.data.amharic_tokenizer import AmharicSubwordTokenizer


class SimpleAmharicGenerator:
    """Simple Amharic text generator using patterns."""
    
    def __init__(self):
        # Initialize tokenizer
        self.tokenizer = AmharicSubwordTokenizer()
        try:
            self.tokenizer.load_vocab("models/tokenizer/amharic_vocab.json")
            print(f"âœ… Loaded Amharic tokenizer (vocab: {self.tokenizer.vocab_size})")
        except FileNotFoundError:
            print("âš ï¸  Using basic tokenizer")
        
        # Common Amharic patterns and continuations
        self.patterns = {
            "áŠ¢á‰µá‹®áŒµá‹«": [
                "á‹á‰¥ áˆ€áŒˆáˆ­ áŠ“á‰µ",
                "á‰ áŠ ááˆªáŠ« á‰€áŠ•á‹µ á‰µáŒˆáŠ›áˆˆá‰½",
                "á‰£áˆˆ á‰¥á‹™ á‰‹áŠ•á‰‹á‹á‰½ áˆ€áŒˆáˆ­ áŠ“á‰µ",
                "á‹¨áŒ¥áŠ•á‰µ áˆ¥áˆáŒ£áŠ” á‹«áˆ‹á‰µ áˆ€áŒˆáˆ­ áŠ“á‰µ",
                "á‰¥á‹™ á‰¥áˆ”áˆ®á‰½áŠ“ á‰¥áˆ”áˆ¨áˆ°á‰¦á‰½ á‹¨áˆšáŠ–áˆ©á‰£á‰µ áˆ€áŒˆáˆ­ áŠ“á‰µ"
            ],
            "áŠ á‹²áˆµ áŠ á‰ á‰£": [
                "á‹¨áŠ¢á‰µá‹®áŒµá‹« á‹‹áŠ“ áŠ¨á‰°áˆ› áŠ“á‰µ",
                "á‹¨áŠ ááˆªáŠ« áˆ˜á‹²áŠ“ á‰°á‰¥áˆ‹ á‰µáŒ áˆ«áˆˆá‰½",
                "á‰ áˆ°áˆ‹áˆ³ á‹“áˆ˜á‰³á‰µ á‹áˆµáŒ¥ á‰ ááŒ¥áŠá‰µ áŠ¥á‹«á‹°áŒˆá‰½ á‰µáŒˆáŠ›áˆˆá‰½",
                "á‹“áˆˆáˆ áŠ á‰€á á‹µáˆ­áŒ…á‰¶á‰½ á‹‹áŠ“ áˆ˜áˆ¥áˆªá‹« á‰¤á‰µ áŠ“á‰µ"
            ],
            "áˆ°áˆ‹áˆ": [
                "áˆˆáˆáˆ‰áˆ áˆ°á‹ á‹­áˆáŠ•",
                "á‹¨áˆ›áŠ•áˆ áŒ áˆ‹á‰µ áŠ á‹­á‹°áˆˆáˆ",
                "á‰ á‹áˆ¸á‰µ á‹¨áˆšáŒˆáŠ áŠ á‹­á‹°áˆˆáˆ",
                "á‰ áá‰…áˆ­ áŠ¥áŠ“ á‰ áˆ˜áŠ¨á‰£á‰ áˆ­ á‹­áŒˆáŠ›áˆ"
            ],
            "á‹ˆáŠ•á‹µáˆœ": [
                "áŠ¥áŠ•á‹´á‰µ áŠáˆ…?",
                "á‰ áˆ°áˆ‹áˆ áŠáˆ…?",
                "áŒ¤áŠ“ á‹­áˆµáŒ¥áˆáŠ•",
                "á‹°áˆ…áŠ“ áŠáˆ…?"
            ],
            "á‰µáˆáˆ…áˆ­á‰µ": [
                "áˆ€áŒˆáˆ­ áˆˆáˆ˜áŒˆáŠ•á‰£á‰µ áŠ áˆµáˆáˆ‹áŒŠ áŠá‹",
                "áˆˆáŠ¥á‹«áŠ•á‹³áŠ•á‹± áˆ°á‹ áˆ˜á‰¥á‰µ áŠá‹",
                "á‹¨á‹ˆá‹°áŠá‰µ á‰°áˆµá‹ áŠá‹",
                "á‰ áŒ¥áˆ«á‰µ áˆ˜áˆ°áŒ á‰µ áŠ áˆˆá‰ á‰µ"
            ],
            "á‹ˆáŒ£á‰¶á‰½": [
                "á‹¨áˆ€áŒˆáˆªá‰± áŠ áŠ•áŒ‹á‹ á‰°áˆµá‹ áŠ“á‰¸á‹",
                "á‰ á‰µáˆáˆ…áˆ­á‰µ áŠ¥áŠ“ á‰ áˆ¥áˆ« áˆ‹á‹­ áˆ›á‰°áŠ®áˆ­ áŠ áˆˆá‰£á‰¸á‹",
                "áˆˆáˆ€áŒˆáˆ«á‰¸á‹ áŠ¥á‹µáŒˆá‰µ áŠ áˆµá‰°á‹‹áŒ½áŠ¦ áˆ›á‹µáˆ¨áŒ áŠ áˆˆá‰£á‰¸á‹"
            ]
        }
        
        # General Amharic sentence patterns
        self.general_patterns = [
            "á‰ á‹šáˆ… áŒŠá‹œ",
            "á‰ á‰°áŒ¨áˆ›áˆªáˆ",
            "áˆµáˆˆá‹šáˆ…",
            "á‰ áˆ˜áˆ†áŠ‘áˆ",
            "á‹­áˆ… áˆ›áˆˆá‰µ",
            "á‰ áŠ áŠ•áƒáˆ©",
            "á‰ áŠ¥áˆ­áŒáŒ¥",
            "á‰ á‰°áˆˆá‹­áˆ"
        ]
        
        # Common Amharic endings
        self.endings = [
            "áŠá‹á¢",
            "áŠ“á‰µá¢",
            "áŠ“á‰¸á‹á¢",
            "á‹­áˆ†áŠ“áˆá¢",
            "áŠ áˆˆá¢",
            "á‰°á‰¥áˆáˆá¢",
            "á‹­áˆ‹áˆá¢",
            "á‹­á‰£áˆ‹áˆá¢"
        ]
    
    def generate_continuation(self, prompt: str) -> str:
        """Generate continuation for a given prompt."""
        prompt = prompt.strip()
        
        # Check for direct patterns
        for key, continuations in self.patterns.items():
            if key in prompt:
                return f"{prompt} {random.choice(continuations)}"
        
        # Generate based on prompt analysis
        if not prompt:
            # Start with a common phrase
            starters = [
                "áŠ¢á‰µá‹®áŒµá‹« á‹á‰¥ áˆ€áŒˆáˆ­ áŠ“á‰µá¢",
                "áŠ á‹²áˆµ áŠ á‰ á‰£ á‹¨áŠ¢á‰µá‹®áŒµá‹« á‹‹áŠ“ áŠ¨á‰°áˆ› áŠ“á‰µá¢",
                "áˆ°áˆ‹áˆ áˆˆáˆáˆ‰áˆ á‹­áˆáŠ•á¢",
                "á‰µáˆáˆ…áˆ­á‰µ áˆˆáˆáˆ‰áˆ áˆ…áŒ»áŠ“á‰µ áˆ˜á‰¥á‰µ áŠá‹á¢",
                "á‹ˆáŒ£á‰¶á‰½ á‹¨áˆ€áŒˆáˆªá‰± á‰°áˆµá‹ áŠ“á‰¸á‹á¢"
            ]
            return random.choice(starters)
        
        # Add a general continuation
        continuation = random.choice(self.general_patterns)
        ending = random.choice(self.endings)
        
        # Try to create a meaningful continuation
        if "áŠ¢á‰µá‹®áŒµá‹«" in prompt or "áˆ€áŒˆáˆ­" in prompt:
            middle = "á‹­áˆ… áˆ€áŒˆáˆ­ á‰¥á‹™ á‹á‰¥ á‰£áˆ…áˆá‰½ á‹«áˆ‰á‰µ"
        elif "á‰µáˆáˆ…áˆ­á‰µ" in prompt or "á‰°áˆ›áˆª" in prompt:
            middle = "á‰µáˆáˆ…áˆ­á‰µ áˆˆáˆáˆ‰áˆ áˆ…áŒ»áŠ“á‰µ áŠ áˆµáˆáˆ‹áŒŠ"
        elif "áˆ°áˆ‹áˆ" in prompt:
            middle = "áˆ°áˆ‹áˆ áˆˆáˆáˆ‰áˆ áˆ°á‹ áŠ áˆµáˆáˆ‹áŒŠ"
        else:
            middle = "á‹­áˆ… áŒ‰á‹³á‹­ á‰ áŒ£áˆ áŠ áˆµáˆáˆ‹áŒŠ"
        
        return f"{prompt} {continuation} {middle} {ending}"
    
    def generate_multiple(self, prompt: str, count: int = 3) -> list:
        """Generate multiple variations."""
        results = []
        for _ in range(count):
            result = self.generate_continuation(prompt)
            results.append(result)
        return results
    
    def test_tokenizer(self, text: str):
        """Test tokenization on generated text."""
        print(f"\nğŸ”¤ Tokenizer Test:")
        print(f"   Text: '{text}'")
        
        # Encode
        tokens = self.tokenizer.encode(text, max_len=64)
        print(f"   Tokens ({len(tokens)}): {tokens[:10]}...")
        
        # Decode
        decoded = self.tokenizer.decode(tokens)
        print(f"   Decoded: '{decoded}'")
        
        return tokens, decoded


def main():
    print("ğŸ¯ Simple Amharic Text Generator")
    print("=" * 40)
    
    generator = SimpleAmharicGenerator()
    
    # Test prompts
    test_prompts = [
        "",
        "áŠ¢á‰µá‹®áŒµá‹«",
        "áŠ á‹²áˆµ áŠ á‰ á‰£", 
        "áˆ°áˆ‹áˆ á‹ˆáŠ•á‹µáˆœ",
        "á‰µáˆáˆ…áˆ­á‰µ",
        "á‹ˆáŒ£á‰¶á‰½"
    ]
    
    print(f"\nğŸ“ Text Generation Tests:")
    for prompt in test_prompts:
        print(f"\nğŸ”¸ Prompt: '{prompt}'")
        result = generator.generate_continuation(prompt)
        print(f"   Result: '{result}'")
        
        # Test tokenizer
        generator.test_tokenizer(result)
    
    print(f"\nğŸ¨ Multiple Variations:")
    variations = generator.generate_multiple("áŠ¢á‰µá‹®áŒµá‹«", count=3)
    for i, var in enumerate(variations, 1):
        print(f"   {i}. {var}")
    
    print(f"\nâœ… Generation test complete!")


if __name__ == "__main__":
    main()