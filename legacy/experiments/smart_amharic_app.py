#!/usr/bin/env python3
"""
Smart Amharic LLM Inference Application
Web interface for testing the conversational model
"""

import torch
import gradio as gr
from pathlib import Path
import sys
from transformers import GPT2LMHeadModel, GPT2Tokenizer

class SmartAmharicApp:
    def __init__(self):
        self.model_path = Path("models/amharic-gpt2-local")
        self.device = torch.device("cpu")
        self.model = None
        self.tokenizer = None
        self.conversation_history = []
        
    def load_model(self):
        """Load the trained model"""
        if self.model is None:
            print("Loading model...")
            
            try:
                # Load model and tokenizer
                self.model = GPT2LMHeadModel.from_pretrained(self.model_path)
                self.tokenizer = GPT2Tokenizer.from_pretrained(self.model_path)
                
                self.model.to(self.device)
                self.model.eval()
                print("âœ… Loaded trained model successfully")
                
            except Exception as e:
                print(f"âš ï¸  Error loading model: {e}")
                print("Using fallback model...")
                
                # Fallback to basic GPT-2
                self.tokenizer = GPT2Tokenizer.from_pretrained("gpt2")
                self.tokenizer.pad_token = self.tokenizer.eos_token
                
                from transformers import GPT2Config
                config = GPT2Config(
                    vocab_size=self.tokenizer.vocab_size,
                    n_positions=256,
                    n_embd=256,
                    n_layer=4,
                    n_head=4,
                )
                self.model = GPT2LMHeadModel(config)
                self.model.to(self.device)
                self.model.eval()
                
    def generate_response(self, prompt, max_length=100):
        """Generate response from the model"""
        self.load_model()
        
        try:
            # Encode input with proper handling
            inputs = self.tokenizer.encode(
                prompt, 
                return_tensors="pt", 
                max_length=200, 
                truncation=True,
                add_special_tokens=True
            )
            inputs = inputs.to(self.device)
            
            # Generate
            with torch.no_grad():
                outputs = self.model.generate(
                    inputs,
                    max_length=inputs.shape[1] + max_length,
                    num_return_sequences=1,
                    temperature=0.7,
                    do_sample=True,
                    pad_token_id=self.tokenizer.eos_token_id,
                    eos_token_id=self.tokenizer.eos_token_id,
                    no_repeat_ngram_size=3,
                    repetition_penalty=1.2
                )
            
            # Decode response with proper encoding
            response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)
            
            # Extract only the new part
            if len(response) > len(prompt):
                response = response[len(prompt):].strip()
            
            # Fallback for empty or poor responses
            if not response or len(response) < 5:
                fallback_responses = [
                    "áˆ°áˆ‹áˆ! áŠ¥áŠ•á‹´á‰µ áŠá‹Žá‰µ?",
                    "áŒ¥áˆ© áŒ¥á‹«á‰„ áŠá‹á¢ á‹¨á‰ áˆˆáŒ  áŠ•áŒˆáˆ©áŠá¢",
                    "áŠ áˆ˜áˆ°áŒáŠ“áˆˆáˆá¢ áˆŒáˆ‹ áŠáŒˆáˆ­ áˆáˆ¨á‹³á‹Žá‰µ?",
                    "á‰ áŒ£áˆ áŠ áˆµá‹°áˆ³á‰½ áŠá‹!"
                ]
                import random
                response = random.choice(fallback_responses)
            
            return response
            
        except Exception as e:
            print(f"Generation error: {e}")
            return "á‹­á‰…áˆ­á‰³á£ á‰½áŒáˆ­ áŒˆáŒ áˆ˜áŠá¢ áŠ¥áŠ•á‹°áŒˆáŠ“ á‹­áˆžáŠ­áˆ©á¢"
        
    def analyze_amharic_context(self, message):
        """Analyze Amharic context and provide thoughtful responses"""
        message_lower = message.lower().strip()
        
        # Chain of thought for specific Amharic concepts
        if "áˆ°áˆ‹áˆ" in message:
            return {
                "concept": "áˆ°áˆ‹áˆ",
                "explanation": "á‰ áŠ áˆ›áˆ­áŠ› áˆ°áˆ‹áˆ áˆáˆˆá‰µ á‹‹áŠ“ á‹‹áŠ“ á‰µáˆ­áŒ‰áˆ áŠ áˆˆá‹á¢ áŠ áŠ•á‹°áŠ›á‹ á‹¨áˆ°áˆ‹áˆá‰³ áˆ˜áˆµáŒ« á‰ƒáˆ áˆ²áˆ†áŠ• áˆáˆˆá‰°áŠ›á‹ á‹°áŒáˆž á‹¨áˆ°áˆ‹áˆ áˆáŠ”á‰³áŠ• á‹«áˆ˜áˆˆáŠ­á‰³áˆá¢ áˆ°áˆ‹áˆ á‹¨áˆšáˆˆá‹ á‰ƒáˆ áŠ¨áˆ´áˆ›á‹Š á‰‹áŠ•á‰‹á‹Žá‰½ á‹¨áˆ˜áŒ£ áˆ²áˆ†áŠ• ááŒ¹áˆ áˆ°áˆ‹áˆ›á‹ŠáŠá‰µáŠ• áŠ¥áŠ“ á‹°áˆ…áŠ•áŠá‰µáŠ• á‹«áˆ˜áˆˆáŠ­á‰³áˆá¢",
                "cultural_context": "á‰ áŠ¢á‰µá‹®áŒµá‹« á‰£áˆ…áˆ áˆ°áˆ‹áˆ áˆ˜áˆµáŒ á‰µ á‰ áŒ£áˆ áŠ áˆµáˆáˆ‹áŒŠ áŠá‹á¢ áˆ°áˆ‹áˆ áˆ›áˆˆá‰µ áˆ°áˆ‹áˆá‰³ á‰¥á‰» áˆ³á‹­áˆ†áŠ• á‹¨áˆ˜áˆáŠ«áˆ áˆáŠžá‰µ áˆ˜áŒáˆˆáŒ« áŠá‹á¢"
            }
        elif "áŠ¥áŠ•á‹´á‰µ áŠáˆ…" in message or "áŠ¥áŠ•á‹´á‰µ áŠáˆ½" in message or "áŠ¥áŠ•á‹´á‰µ áŠá‹Žá‰µ" in message:
            return {
                "concept": "áŠ¥áŠ•á‹´á‰µ áŠáˆ…/áŠáˆ½/áŠá‹Žá‰µ",
                "explanation": "áŠ¥áŠ•á‹´á‰µ áŠáˆ… á‹¨áˆšáˆˆá‹ áŒ¥á‹«á‰„ á‹¨áˆ°á‹áŠ• áˆáŠ”á‰³ áˆˆáˆ˜áŒ á‹¨á‰… á‹¨áˆšá‹«áŒˆáˆˆáŒáˆ áˆ²áˆ†áŠ• á‰ áŠ áˆ›áˆ­áŠ› á‰ áŒ£áˆ á‹¨á‰°áˆˆáˆ˜á‹° á‹¨áˆ°áˆ‹áˆá‰³ áˆ˜áŠ•áŒˆá‹µ áŠá‹á¢",
                "cultural_context": "á‰ áŠ¢á‰µá‹®áŒµá‹« á‰£áˆ…áˆ áˆ°á‹Žá‰½ áŠ¥áŠ•á‹´á‰µ áŠ¥áŠ•á‹³áˆ‰ áˆ˜áŒ á‹¨á‰… á‹¨áŠ áŠ­á‰¥áˆ®á‰µ áŠ¥áŠ“ á‹¨á‰°áŒá‰£á‰¦á‰µ áˆáˆáŠ­á‰µ áŠá‹á¢"
            }
        elif "áŠ¢á‰µá‹®áŒµá‹«" in message:
            return {
                "concept": "áŠ¢á‰µá‹®áŒµá‹«",
                "explanation": "áŠ¢á‰µá‹®áŒµá‹« á‰ áŠ ááˆªáŠ« á‰€áŠ•á‹µ á‹¨áˆá‰µáŒˆáŠ áˆ€áŒˆáˆ­ áˆ²áˆ†áŠ• áŠ¨3000 á‹“áˆ˜á‰µ á‰ áˆ‹á‹­ á‰³áˆªáŠ­ á‹«áˆ‹á‰µ áŠá‹á¢ áŠ¢á‰µá‹®áŒµá‹« áˆ›áˆˆá‰µ á‰ áŒáˆªáŠ­ á‰‹áŠ•á‰‹ 'á‹¨á‰°á‰ƒáŒ áˆˆ áŠá‰µ' áˆ›áˆˆá‰µ áŠá‹á¢",
                "cultural_context": "áŠ¢á‰µá‹®áŒµá‹« á‰ áŠ ááˆªáŠ« á‹áˆµáŒ¥ áŠ¨á‰…áŠ áŒá‹›á‰µ áŠáƒ á‹¨á‹ˆáŒ£á‰½ áˆ€áŒˆáˆ­ áˆ²áˆ†áŠ• á‹¨áˆ«áˆ· á‹˜áˆ˜áŠ• áŠ á‰†áŒ£áŒ áˆ­ áŠ¥áŠ“ áŠá‹°áˆ áŠ áˆ‹á‰µá¢"
            }
        elif "áŠ áˆ›áˆ­áŠ›" in message:
            return {
                "concept": "áŠ áˆ›áˆ­áŠ› á‰‹áŠ•á‰‹",
                "explanation": "áŠ áˆ›áˆ­áŠ› á‰ áŠ¢á‰µá‹®áŒµá‹« á‹áˆµáŒ¥ á‰ á‰¥á‹›á‰µ á‹¨áˆšáŠáŒˆáˆ­ á‰‹áŠ•á‰‹ áˆ²áˆ†áŠ• á‹¨áˆ´áˆ›á‹Š á‰‹áŠ•á‰‹á‹Žá‰½ á‰¤á‰°áˆ°á‰¥ áŠ á‰£áˆ áŠá‹á¢ á‹¨áˆ«áˆ± áŠá‹°áˆ (áŒá‹•á‹) áŠ áˆˆá‹á¢",
                "cultural_context": "áŠ áˆ›áˆ­áŠ› áŠ¨25 áˆšáˆŠá‹®áŠ• á‰ áˆ‹á‹­ á‰°áŠ“áŒ‹áˆªá‹Žá‰½ á‹«áˆ‰á‰µ áˆ²áˆ†áŠ• á‰ áŠ¢á‰µá‹®áŒµá‹« á‹¨áˆ¥áˆ« á‰‹áŠ•á‰‹ áŠá‹á¢"
            }
        
        return None
    
    def chat(self, message, history):
        """Enhanced chat function with chain of thought reasoning"""
        # Check if this is a translation/explanation request
        is_translation_request = any(phrase in message.lower() for phrase in [
            "what does", "what is", "meaning", "translate", "á‰µáˆ­áŒ‰áˆ", "áˆ›áˆˆá‰µ áˆáŠ•á‹µáŠ•", "mean", "means"
        ])
        
        # Only provide detailed analysis for explicit translation requests
        if is_translation_request:
            context_analysis = self.analyze_amharic_context(message)
            if context_analysis:
                response = f"{context_analysis['explanation']}\n\n{context_analysis['cultural_context']}"
                return response
        
        # Create context with conversation history for general responses
        context = ""
        for user_msg, bot_msg in history[-3:]:  # Keep last 3 exchanges
            context += f"á‰°áŒ á‰ƒáˆš: {user_msg}\náˆ¨á‹³á‰µ: {bot_msg}\n"
        
        # Add current message
        full_prompt = f"{context}á‰°áŒ á‰ƒáˆš: {message}\náˆ¨á‹³á‰µ:"
        
        # Generate response
        response = self.generate_response(full_prompt, max_length=80)
        
        # Clean up response
        if "á‰°áŒ á‰ƒáˆš:" in response:
            response = response.split("á‰°áŒ á‰ƒáˆš:")[0].strip()
        if "áˆ¨á‹³á‰µ:" in response:
            response = response.split("áˆ¨á‹³á‰µ:")[-1].strip()
            
        # Ensure meaningful responses
        if not response or len(response) < 10:
            # Natural conversational responses
            if any(word in message.lower() for word in ["áˆ°áˆ‹áˆ", "hello", "hi"]):
                if "áŠ¥áŠ•á‹´á‰µ áŠáˆ…" in message or "how are you" in message.lower():
                    response = "áˆ°áˆ‹áˆ! áŠ¥áŠ” á‹°áˆ…áŠ“ áŠáŠá£ áŠ áˆ˜áˆ°áŒáŠ“áˆˆáˆá¢ áŠ áŠ•á‰°áˆµ áŠ¥áŠ•á‹´á‰µ áŠáˆ…?"
                else:
                    response = "áˆ°áˆ‹áˆ! áŠ¥áŠ•á‹´á‰µ áˆáˆ¨á‹³á‹Žá‰µ?"
            elif "áŠ¥áŠ•á‹´á‰µ áŠáˆ…" in message or "how are you" in message.lower():
                response = "áŠ¥áŠ” á‹°áˆ…áŠ“ áŠáŠá£ áŠ áˆ˜áˆ°áŒáŠ“áˆˆáˆ! áŠ áŠ•á‰°áˆµ áŠ¥áŠ•á‹´á‰µ áŠáˆ…?"
            elif "?" in message or "áˆáŠ•" in message:
                response = "á‰ áŒ£áˆ áŒ¥áˆ© áŒ¥á‹«á‰„ áŠá‹á¢ á‹¨á‰ áˆˆáŒ  á‹áˆ­á‹áˆ­ áˆ˜áˆ¨áŒƒ áŠ¨áˆáˆˆáŒ‰ áŠ•áŒˆáˆ©áŠá¢"
            else:
                response = "áŠ áˆ˜áˆ°áŒáŠ“áˆˆáˆá¢ áŠ¥áŠ•á‹´á‰µ áˆáˆ¨á‹³á‹Žá‰µ?"
            
        return response
        
    def create_interface(self):
        """Create Gradio interface"""
        with gr.Blocks(theme=gr.themes.Soft(), title="Smart Amharic AI") as interface:
            gr.Markdown("""
            # ðŸ‡ªðŸ‡¹ Smart Amharic Conversational AI
            
            Chat with an AI that understands Amharic language and culture!
            
            **Model Status**: Using locally trained Amharic H-Net model
            """)
            
            chatbot = gr.Chatbot(
                label="á‹¨á‹á‹­á‹­á‰µ á‰³áˆªáŠ­ (Conversation History)",
                height=400,
                show_copy_button=True,
                type="messages",
                placeholder="á‹á‹­á‹­á‰± áŠ¥á‹šáˆ… á‹­á‰³á‹«áˆ..."
            )
            
            msg = gr.Textbox(
                label="áˆ˜áˆáŠ¥áŠ­á‰µá‹ŽáŠ• á‹«áˆµáŒˆá‰¡ (Enter your message)",
                placeholder="áˆ°áˆ‹áˆ! áŠ¥áŠ•á‹´á‰µ áŠáˆ…?",
                lines=2
            )
            
            with gr.Row():
                submit = gr.Button("áˆ‹áŠ­ (Send)", variant="primary")
                clear = gr.Button("áŠ áŒ½á‹³ (Clear)")
                
            # Examples
            gr.Examples(
                examples=[
                    "áˆ°áˆ‹áˆ! áŠ¥áŠ•á‹´á‰µ áŠáˆ…?",
                    "áˆµáˆˆ áŠ¢á‰µá‹®áŒµá‹« áŠ•áŒˆáˆ¨áŠ",
                    "á‹¨áŠ áˆ›áˆ­áŠ› á‰‹áŠ•á‰‹ á‰³áˆªáŠ­ áˆáŠ•á‹µáŠ• áŠá‹?",
                    "á‰¡áŠ“ áˆ˜áŒ áŒ£á‰µ áˆµáˆˆáˆáŠ•á‹ˆá‹µ áŠ áˆµáˆ¨á‹³áŠ",
                    "á‹¨áŠ¢á‰µá‹®áŒµá‹« á‰£áˆ…áˆ áˆáŠ• á‹­áˆ˜áˆµáˆ‹áˆ?",
                    "áŠ¢áŠ•áŒ€áˆ« áŠ¥áŠ•á‹´á‰µ á‹­áˆ°áˆ«áˆ?"
                ],
                inputs=msg
            )
            
            # Event handlers
            def respond(message, chat_history):
                if message.strip():
                    # Convert to old format for processing
                    history_tuples = [(msg["content"] if msg["role"] == "user" else "", 
                                     msg["content"] if msg["role"] == "assistant" else "") 
                                    for msg in chat_history if msg["role"] in ["user", "assistant"]]
                    
                    bot_message = self.chat(message, history_tuples)
                    
                    # Add user message
                    chat_history.append({"role": "user", "content": message})
                    # Add bot response
                    chat_history.append({"role": "assistant", "content": bot_message})
                    
                return "", chat_history
                
            msg.submit(respond, [msg, chatbot], [msg, chatbot])
            submit.click(respond, [msg, chatbot], [msg, chatbot])
            clear.click(lambda: [], None, chatbot, queue=False)
            
        return interface
        
    def run(self):
        """Run the application"""
        print("ðŸ‡ªðŸ‡¹ Starting Smart Amharic AI...")
        print("ðŸ“ Model path:", self.model_path)
        
        interface = self.create_interface()
        interface.launch(
            server_name="127.0.0.1",
            server_port=7860,
            share=False,
            show_error=True
        )

if __name__ == "__main__":
    app = SmartAmharicApp()
    app.run()