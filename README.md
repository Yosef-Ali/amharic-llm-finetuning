# ğŸ‡ªğŸ‡¹ Amharic H-Net: Production-Ready AI Text Generation

[![Model Status](https://img.shields.io/badge/Model-Production%20Ready-brightgreen.svg)](README.md)
[![API Status](https://img.shields.io/badge/API-Online-success.svg)](http://localhost:8000/docs)
[![Quality Score](https://img.shields.io/badge/Quality-0.619Â±0.013-blue.svg)](test_results.json)

A production-ready Amharic text generation system using Hierarchical Network (H-Net) architecture with comprehensive evaluation, REST API, and web interface.

## ğŸš€ Quick Start

### 1. Start the API Server
```bash
python api_server.py
```

### 2. Open Web Interface
```bash
# Open web_interface.html in your browser
# or serve via HTTP server:
python -m http.server 8080
```

### 3. Test the API
```bash
curl -X POST "http://localhost:8000/generate" \
  -H "Content-Type: application/json" \
  -d '{"prompt": "áŠ¢á‰µá‹®áŒµá‹«", "length": 50}'
```

## ğŸ“Š Model Performance

| Metric | Score | Details |
|--------|-------|---------|
| **Overall Quality** | 0.619 Â± 0.013 | Comprehensive text quality |
| **Amharic Ratio** | 98% | Authentic Amharic generation |
| **Fluency Score** | 0.667 | Natural language flow |
| **Coherence Score** | 0.800 | Logical text structure |
| **Test Loss** | 8.121 | Model convergence |

## ğŸ—ï¸ Architecture

### Core Components
- **H-Net Model**: 6.85M parameter Hierarchical Network
- **Amharic Tokenizer**: 3,087 subword vocabulary
- **Quality Evaluator**: Multi-metric assessment system
- **REST API**: FastAPI-based production server
- **Web Interface**: Interactive text generation UI

### Technology Stack
- **Backend**: Python 3.9+, PyTorch, FastAPI
- **Frontend**: HTML5, CSS3, JavaScript (Vanilla)
- **Deployment**: Docker, Docker Compose, Nginx
- **Evaluation**: Custom Amharic-specific metrics

## ğŸ“ Project Structure

```
Amharic-Hnet-Qwin/
â”œâ”€â”€ src/amharichnet/           # Core model implementation
â”‚   â”œâ”€â”€ models/hnet.py         # H-Net model architecture
â”‚   â”œâ”€â”€ data/                  # Data processing
â”‚   â”œâ”€â”€ evaluation/            # Quality assessment
â”‚   â””â”€â”€ train/                 # Training pipeline
â”œâ”€â”€ models/                    # Trained models & tokenizer
â”œâ”€â”€ data/                      # Training datasets
â”œâ”€â”€ configs/                   # Model configurations
â”œâ”€â”€ api_server.py             # REST API server
â”œâ”€â”€ generate.py               # Text generation CLI
â”œâ”€â”€ web_interface.html        # Web UI
â”œâ”€â”€ test_api.py              # API testing suite
â””â”€â”€ docker-compose.yml       # Production deployment
```

## ğŸ¯ Features

### Text Generation
- **Multiple Categories**: General, news, educational, cultural, conversation
- **Context-Aware**: Intelligent prompt continuation
- **Quality Control**: Real-time evaluation scores
- **Flexible Length**: 10-200 words per generation

### API Endpoints
- `POST /generate` - Single text generation
- `POST /generate/batch` - Batch processing (up to 10)
- `POST /evaluate` - Text quality assessment
- `GET /health` - System health check
- `GET /stats` - Usage statistics

### Web Interface
- **Interactive UI**: Beautiful, responsive design
- **Real-time Generation**: Instant text creation
- **Quality Metrics**: Live performance scores
- **Example Prompts**: Quick-start templates
- **Mobile Friendly**: Works on all devices

## ğŸ”§ Quick Start (Alternative)

```bash
# Clone and setup
git clone <your-repo-url>
cd Amharic-Hnet-Qwin

# Install dependencies
pip install pyyaml pydantic pytest

# Train the model
PYTHONPATH=src python -m amharichnet.cli train --config configs/base.yaml

# Check outputs
ls -la outputs/run/
cat outputs/run/metrics.json
```

## ğŸ“ Project Structure

```
Amharic-Hnet-Qwin/
â”œâ”€â”€ src/amharichnet/           # ğŸ¯ Clean implementation (main)
â”‚   â”œâ”€â”€ cli.py                 # Command-line interface
â”‚   â”œâ”€â”€ data/                  # Data loading and processing
â”‚   â”œâ”€â”€ models/                # Model architectures
â”‚   â”œâ”€â”€ train/                 # Training pipeline
â”‚   â””â”€â”€ utils/                 # Configuration and utilities
â”œâ”€â”€ configs/                   # âš™ï¸ Configuration files
â”‚   â””â”€â”€ base.yaml
â”œâ”€â”€ tests/                     # ğŸ§ª Test suite
â”‚   â”œâ”€â”€ unit/                  # Unit tests
â”‚   â””â”€â”€ smoke/                 # Integration tests
â”œâ”€â”€ data/                      # ğŸ“Š Organized datasets
â”‚   â”œâ”€â”€ raw/collected_articles/ # Original scraped data (962 articles)
â”‚   â”œâ”€â”€ processed/             # Cleaned and processed data
â”‚   â””â”€â”€ training/              # Training-ready datasets
â”œâ”€â”€ models/                    # ğŸ¤– Model checkpoints and artifacts
â”œâ”€â”€ docs/                      # ğŸ“š All documentation
â”œâ”€â”€ legacy/                    # ğŸ—„ï¸ Archived implementations
â”‚   â”œâ”€â”€ amharic-hnet/         # Original implementation
â”‚   â”œâ”€â”€ old_training_scripts/ # Legacy training scripts
â”‚   â””â”€â”€ experiments/          # Experimental code and utilities
â””â”€â”€ [Essential files only]    # Clean root directory
```

## ğŸ¯ Core Features

### Clean Implementation (`src/amharichnet/`)
- **Single entry point**: CLI-based interface
- **Modular design**: Separate data, models, training, utils
- **Configuration-driven**: YAML-based configs
- **Reproducible**: Deterministic seeding and checkpointing
- **Resume support**: Automatic checkpoint loading

### Training Pipeline
```bash
# Basic training
python -m amharichnet.cli train --config configs/base.yaml

# Check training progress
cat outputs/run/metrics.json
# {"steps": 100, "final_loss": 2.45, "val_loss": 2.67}

# Resume from checkpoint
# Set model.checkpoint: outputs/run/checkpoints/ckpt.pt in config
python -m amharichnet.cli train --config configs/base.yaml
```

### Data Organization
- **Raw Data**: 962 collected Amharic articles
- **Processed Data**: Cleaned and formatted for training
- **Training Data**: Ready-to-use datasets with proper splits

## ğŸ§ª Testing

```bash
# Run all tests
pytest tests/

# Run specific test suites
pytest tests/unit/      # Unit tests
pytest tests/smoke/     # Integration tests
```

## ğŸ“Š Data Statistics

- **Articles Collected**: 962 raw articles
- **Processing Pipeline**: Automated cleaning and validation
- **Training Ready**: Structured datasets in `data/` directory
- **Legacy Preserved**: All original work archived in `legacy/`

## ğŸ—ï¸ Architecture

### Main Implementation
- **src/amharichnet/**: Modern, clean implementation
- **Pydantic configs**: Type-safe configuration management
- **Modular design**: Easy to extend and maintain
- **CLI interface**: Simple command-line usage

### Legacy Archive
- **legacy/amharic-hnet/**: Original comprehensive implementation
- **legacy/old_training_scripts/**: Various training approaches
- **legacy/experiments/**: Experimental code and utilities

## ğŸ”§ Configuration

Edit `configs/base.yaml`:

```yaml
data:
  train_path: "data/training/train.jsonl"
  val_path: "data/training/val.jsonl"
  batch_size: 8

model:
  name: "TinyHNet"
  hidden_dim: 256
  num_layers: 4
  checkpoint: null  # Set to checkpoint path to resume

train:
  epochs: 10
  lr: 0.001
  output_dir: "outputs"
```

## ğŸ“š Documentation

### ğŸ¯ **Start Here (Post-Refactor)**
- **[Clean Architecture Setup](docs/CLEAN_ARCHITECTURE_SETUP.md)**: Quick setup for the `src/amharichnet/` implementation
- **[Refactor Workflow Guide](docs/REFACTOR_WORKFLOW_GUIDE.md)**: Complete step-by-step workflow (train, resume, test, extend)

### ğŸ“– **Comprehensive Documentation**
- `docs/README.md`: Detailed project documentation  
- `docs/IMPLEMENTATION_GUIDE.md`: Implementation details
- `docs/PROJECT_STRUCTURE.md`: Architecture overview
- `docs/ENVIRONMENT_SETUP.md`: Environment configuration
- And 10+ other guides for comprehensive coverage

## ğŸš€ Next Steps

1. **Train your model**: `python -m amharichnet.cli train --config configs/base.yaml`
2. **Explore legacy code**: Check `legacy/` for comprehensive implementations
3. **Extend functionality**: Add inference and evaluation CLI commands
4. **Scale up**: Use larger datasets from `data/raw/collected_articles/`

## ğŸ“„ License

MIT License - see `LICENSE` file for details.

---

**ğŸ¯ Clean Architecture â€¢ ğŸ“Š Rich Data â€¢ ğŸ§ª Well Tested â€¢ ğŸ—„ï¸ Legacy Preserved**

*Building production-ready Amharic AI with clean, maintainable code.*